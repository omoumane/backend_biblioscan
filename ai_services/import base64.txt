import base64
import cv2
import torch
import numpy as np
from io import BytesIO
from PIL import Image
from fastapi import FastAPI, File, UploadFile
from fastapi.responses import StreamingResponse
from ultralytics import YOLO


app = FastAPI()

MODEL_PATH = "./models/bookshelf_best.pt"
MODEL_IMG_SIZE = 640
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

print("ðŸ” VÃ©rification de l'environnement PyTorch :")
print(f"âž¡ Device utilisÃ© : {DEVICE}")
if DEVICE == "cuda":
    print(f"ðŸ’ª GPU : {torch.cuda.get_device_name(0)}")

print("\nðŸ”„ Chargement du modÃ¨le...")
model = YOLO(MODEL_PATH)
model.to(DEVICE)
print(f"âœ… ModÃ¨le prÃªt sur device: {DEVICE}")
print(f"ðŸ“¦ ModÃ¨le chargÃ© : {MODEL_PATH}")

# ============================================================
# ðŸ§© Fonctions utilitaires
# ============================================================
def _xyxy_to_int(box):
    x1 = int(round(box[0])); y1 = int(round(box[1]))
    x2 = int(round(box[2])); y2 = int(round(box[3]))
    return x1, y1, x2, y2

def _filter_spines_by_ratio(dets, min_ratio=1.6):
    """Garde les boÃ®tes 'livres' avec un ratio H/W suffisant (tranche)."""
    keep = []
    for d in dets:
        x1, y1, x2, y2 = d["box"]["x1"], d["box"]["y1"], d["box"]["x2"], d["box"]["y2"]
        w = max(1.0, x2 - x1)
        h = max(1.0, y2 - y1)
        if (h / w) >= min_ratio:
            keep.append(d)
    return keep

# ============================================================
# ðŸ“· Endpoint : DÃ©tection simple (JSON)
# ============================================================
@app.post("/detect")
async def detect(
    file: UploadFile = File(...),
    conf: float = 0.6,
    iou: float = 0.5
):
    image_bytes = await file.read()
    nparr = np.frombuffer(image_bytes, np.uint8)
    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

    results = model.predict(img, conf=conf, iou=iou, imgsz=MODEL_IMG_SIZE, device=DEVICE, verbose=False)
    r = results[0]

    H, W = img.shape[:2]
    dets = []
    if len(r.boxes):
        for box, score, cls in zip(r.boxes.xyxy.cpu().numpy(), r.boxes.conf.cpu().numpy(), r.boxes.cls.cpu().numpy()):
            x1, y1, x2, y2 = _xyxy_to_int(box)
            dets.append({
                "box": {"x1": float(x1), "y1": float(y1), "x2": float(x2), "y2": float(y2)},
                "confidence": float(round(float(score), 3)),
                "class_id": int(cls),
                "class_name": r.names[int(cls)]
            })

    return {
        "image_size": {"width": W, "height": H},
        "num_detections": len(dets),
        "detections": dets,
        "model": {"path": MODEL_PATH, "device": DEVICE, "imgsz": MODEL_IMG_SIZE}
    }

# ============================================================
# âœ‚ Endpoint : DÃ©tection + crops prÃªts pour OCR
# ============================================================
@app.post("/detect_crops")
async def detect_crops(
    file: UploadFile = File(...),
    conf: float = 0.6,
    iou: float = 0.5,
    min_ratio: float = 1.6,
    margin: int = 6,
    sort_left_to_right: bool = True
):
    image_bytes = await file.read()
    nparr = np.frombuffer(image_bytes, np.uint8)
    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

    results = model.predict(img, conf=conf, iou=iou, imgsz=MODEL_IMG_SIZE, device=DEVICE, verbose=False)
    r = results[0]
    boxes = r.boxes.xyxy.cpu().numpy() if len(r.boxes) else []
    scores = r.boxes.conf.cpu().numpy() if len(r.boxes) else []
    cls_ids = r.boxes.cls.cpu().numpy().astype(int) if len(r.boxes) else []

    H, W = img.shape[:2]
    dets = []
    names = r.names
    for (x1, y1, x2, y2), s, c in zip(boxes, scores, cls_ids):
        dets.append({
            "box": {"x1": float(x1), "y1": float(y1), "x2": float(x2), "y2": float(y2)},
            "confidence": float(round(float(s), 3)),
            "class_id": int(c),
            "class_name": names.get(int(c), str(int(c)))
        })

    dets = _filter_spines_by_ratio(dets, min_ratio=min_ratio)
    if sort_left_to_right:
        dets.sort(key=lambda d: d["box"]["x1"])

    crops = []
    for d in dets:
        x1, y1, x2, y2 = _xyxy_to_int([d["box"]["x1"], d["box"]["y1"], d["box"]["x2"], d["box"]["y2"]])
        x1 = max(0, x1 - margin)
        y1 = max(0, y1 - margin)
        x2 = min(W - 1, x2 + margin)
        y2 = min(H - 1, y2 + margin)
        crop = img[y1:y2, x1:x2]
        pil_im = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))
        buf = BytesIO()
        pil_im.save(buf, format="JPEG", quality=92)
        crops.append({
            "meta": d,
            "jpeg_base64": base64.b64encode(buf.getvalue()).decode("utf-8")
        })

    return {
        "image_size": {"width": W, "height": H},
        "num_detections": len(dets),
        "crops": crops
    }

# ============================================================
# ðŸ–¼ Endpoint : Image annotÃ©e
# ============================================================
@app.post("/detect_image")
async def detect_image(
    file: UploadFile = File(...),
    conf: float = 0.6,
    iou: float = 0.5
):
    """Renvoie l'image annotÃ©e (JPEG)."""
    image_bytes = await file.read()
    nparr = np.frombuffer(image_bytes, np.uint8)
    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

    results = model.predict(img, conf=conf, iou=iou, imgsz=MODEL_IMG_SIZE, device=DEVICE, verbose=False)
    r = results[0]

    if len(r.boxes):
        for box, score, cls in zip(r.boxes.xyxy.cpu().numpy(), r.boxes.conf.cpu().numpy(), r.boxes.cls.cpu().numpy()):
            x1, y1, x2, y2 = _xyxy_to_int(box)
            label = f"{r.names[int(cls)]} {score:.2f}"
            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)
            cv2.putText(img, label, (x1, max(0, y1 - 6)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)

    _, jpg = cv2.imencode(".jpg", img)
    return StreamingResponse(BytesIO(jpg.tobytes()), media_type="image/jpeg")